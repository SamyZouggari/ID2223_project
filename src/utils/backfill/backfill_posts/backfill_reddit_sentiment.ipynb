{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7586a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CryptoBERT...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hopsworks\n",
    "import os\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import utils.reddit_scraper as utils\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb369a",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "SUBREDDITS = {\n",
    "    'solana': 'SOL',\n",
    "}\n",
    "\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2025-12-31'\n",
    "\n",
    "def get_weekly_ranges(start, end):\n",
    "    \"\"\"Generate monthly date ranges\"\"\"\n",
    "    ranges = []\n",
    "    current = datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_dt = datetime.strptime(end, '%Y-%m-%d')\n",
    "    \n",
    "    while current < end_dt:\n",
    "        next_week = current + timedelta(days=1)\n",
    "\n",
    "        if next_week > end_dt:\n",
    "            next_week = end_dt\n",
    "        \n",
    "        ranges.append((\n",
    "            current.strftime('%Y-%m-%d'),\n",
    "            next_week.strftime('%Y-%m-%d')\n",
    "        ))\n",
    "        \n",
    "        current = next_week\n",
    "    \n",
    "    return ranges\n",
    "\n",
    "# Generate date ranges\n",
    "date_ranges = get_weekly_ranges(START_DATE, END_DATE)\n",
    "print(f\"üìÖ Will fetch {len(date_ranges)} weeks of data\")\n",
    "print(f\"   From {date_ranges[0][0]} to {date_ranges[-1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d237ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all posts month by month\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "for subreddit in SUBREDDITS.keys():\n",
    "    print(f\"\\n==================== Subreddit: r/{subreddit} ====================\")\n",
    "    for i, (start, end) in enumerate(date_ranges, 1):\n",
    "        print(f\"\\nüìÜ [{i}/{len(date_ranges)}] Fetching {start} to {end}...\")\n",
    "        \n",
    "        weekly_posts = reddit_scraper.fetch_pushshift_posts(\n",
    "            subreddit=subreddit,\n",
    "        start_date=start,\n",
    "        end_date=end,\n",
    "        limit=20\n",
    "    )\n",
    "    \n",
    "        if weekly_posts:\n",
    "            all_posts.extend(weekly_posts)\n",
    "            print(f\"   ‚úÖ Added {len(weekly_posts)} posts (Total: {len(all_posts)})\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No posts found for this period\")\n",
    "        \n",
    "        # Rate limiting (be nice to API)\n",
    "        time.sleep(1)\n",
    "\n",
    "print(f\"\\nüéâ Backfill complete!\")\n",
    "print(f\"üìä Total posts fetched: {len(all_posts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f06920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_posts)\n",
    "\n",
    "df = df[['subreddit', 'title', 'selftext', 'score', 'num_comments', 'created_utc']]\n",
    "df['crypto'] = df['subreddit'].map(SUBREDDITS)\n",
    "df = df[['crypto', 'title', 'selftext', 'score', 'num_comments', 'created_utc']]\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "\n",
    "# Sauvegarder\n",
    "output_file = 'reddit_posts_backfill.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ SUCCESS!\")\n",
    "print(f\"üìä Total posts: {len(df)}\")\n",
    "print(f\"üíæ Saved to: {output_file}\")\n",
    "print(f\"\\nPosts par crypto:\")\n",
    "print(df['crypto'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('reddit_posts_backfill.csv', parse_dates=['created_utc'])\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df[\"selftext\"] = df[\"selftext\"].replace(['[deleted]', '[removed]'], '')\n",
    "df[\"selftext\"] = df[\"selftext\"].fillna('')\n",
    "df['crypto'] = df['crypto'].astype(str)\n",
    "df['title'] = df['title'].astype(str)\n",
    "df['selftext'] = df['selftext'].astype(str)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "fg = fs.create_feature_group(\n",
    "    \"reddit_posts_backfill\",\n",
    "    version=1,\n",
    "    description=\"Reddit posts backfill data\",\n",
    "    primary_key=[\"created_utc\"],\n",
    "    event_time=\"created_utc\",\n",
    "    online_enabled=False\n",
    "    )\n",
    "\n",
    "fg.save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15eef81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-04 00:17:56,076 INFO: Initializing external client\n",
      "2026-01-04 00:17:56,079 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-04 00:17:57,235 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-04 00:17:58,198 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279131\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.96s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crypto</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOL</td>\n",
       "      <td>Is anyone staking Sol via Marinade&amp;gt;Saber&amp;gt...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-02-28 17:44:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOL</td>\n",
       "      <td>SOLANA rocks...</td>\n",
       "      <td>What do you guys think about SOL?  From the pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-08-08 14:48:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOL</td>\n",
       "      <td>Star Atlas' \"Never Alone\": An Immersive Journe...</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-12 12:08:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOL</td>\n",
       "      <td>Microsoft App Store approved a scammer app dis...</td>\n",
       "      <td>A fake @Ledger Live app on the official @Micro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-05 07:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOL</td>\n",
       "      <td>SugarRush - An open-source free web app projec...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-23 18:11:23+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  crypto                                              title  \\\n",
       "0    SOL  Is anyone staking Sol via Marinade&gt;Saber&gt...   \n",
       "1    SOL                                    SOLANA rocks...   \n",
       "2    SOL  Star Atlas' \"Never Alone\": An Immersive Journe...   \n",
       "3    SOL  Microsoft App Store approved a scammer app dis...   \n",
       "4    SOL  SugarRush - An open-source free web app projec...   \n",
       "\n",
       "                                            selftext  score  num_comments  \\\n",
       "0                                                         4             9   \n",
       "1  What do you guys think about SOL?  From the pe...      0            50   \n",
       "2                                                        12             1   \n",
       "3  A fake @Ledger Live app on the official @Micro...      1             1   \n",
       "4                                                         1             1   \n",
       "\n",
       "                created_utc  \n",
       "0 2022-02-28 17:44:51+00:00  \n",
       "1 2022-08-08 14:48:47+00:00  \n",
       "2 2023-05-12 12:08:07+00:00  \n",
       "3 2023-11-05 07:00:00+00:00  \n",
       "4 2022-08-23 18:11:23+00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "fg = fs.get_feature_group(\"reddit_posts_backfill\", version=1)\n",
    "\n",
    "df = fg.read()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49700757",
   "metadata": {},
   "source": [
    "# Create the feature of aggregated sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ab198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "   Progress: 0/28750 (0%)\n",
      "   Progress: 320/28750 (1%)\n",
      "   Progress: 640/28750 (2%)\n",
      "   Progress: 960/28750 (3%)\n",
      "   Progress: 1280/28750 (4%)\n",
      "   Progress: 1600/28750 (5%)\n",
      "   Progress: 1920/28750 (6%)\n",
      "   Progress: 2240/28750 (7%)\n",
      "   Progress: 2560/28750 (8%)\n",
      "   Progress: 2880/28750 (10%)\n",
      "   Progress: 3200/28750 (11%)\n",
      "   Progress: 3520/28750 (12%)\n",
      "   Progress: 3840/28750 (13%)\n",
      "   Progress: 4160/28750 (14%)\n",
      "   Progress: 4480/28750 (15%)\n",
      "   Progress: 4800/28750 (16%)\n",
      "   Progress: 5120/28750 (17%)\n",
      "   Progress: 5440/28750 (18%)\n",
      "   Progress: 5760/28750 (20%)\n",
      "   Progress: 6080/28750 (21%)\n",
      "   Progress: 6400/28750 (22%)\n",
      "   Progress: 6720/28750 (23%)\n",
      "   Progress: 7040/28750 (24%)\n",
      "   Progress: 7360/28750 (25%)\n",
      "   Progress: 7680/28750 (26%)\n",
      "   Progress: 8000/28750 (27%)\n",
      "   Progress: 8320/28750 (28%)\n",
      "   Progress: 8640/28750 (30%)\n",
      "   Progress: 8960/28750 (31%)\n",
      "   Progress: 9280/28750 (32%)\n",
      "   Progress: 9600/28750 (33%)\n",
      "   Progress: 9920/28750 (34%)\n",
      "   Progress: 10240/28750 (35%)\n",
      "   Progress: 10560/28750 (36%)\n",
      "   Progress: 10880/28750 (37%)\n",
      "   Progress: 11200/28750 (38%)\n",
      "   Progress: 11520/28750 (40%)\n",
      "   Progress: 11840/28750 (41%)\n",
      "   Progress: 12160/28750 (42%)\n",
      "   Progress: 12480/28750 (43%)\n",
      "   Progress: 12800/28750 (44%)\n",
      "   Progress: 13120/28750 (45%)\n",
      "   Progress: 13440/28750 (46%)\n",
      "   Progress: 13760/28750 (47%)\n",
      "   Progress: 14080/28750 (48%)\n",
      "   Progress: 14400/28750 (50%)\n",
      "   Progress: 14720/28750 (51%)\n",
      "   Progress: 15040/28750 (52%)\n",
      "   Progress: 15360/28750 (53%)\n",
      "   Progress: 15680/28750 (54%)\n",
      "   Progress: 16000/28750 (55%)\n",
      "   Progress: 16320/28750 (56%)\n",
      "   Progress: 16640/28750 (57%)\n",
      "   Progress: 16960/28750 (58%)\n",
      "   Progress: 17280/28750 (60%)\n",
      "   Progress: 17600/28750 (61%)\n",
      "   Progress: 17920/28750 (62%)\n",
      "   Progress: 18240/28750 (63%)\n",
      "   Progress: 18560/28750 (64%)\n",
      "   Progress: 18880/28750 (65%)\n",
      "   Progress: 19200/28750 (66%)\n",
      "   Progress: 19520/28750 (67%)\n",
      "   Progress: 19840/28750 (69%)\n",
      "   Progress: 20160/28750 (70%)\n",
      "   Progress: 20480/28750 (71%)\n",
      "   Progress: 20800/28750 (72%)\n",
      "   Progress: 21120/28750 (73%)\n",
      "   Progress: 21440/28750 (74%)\n",
      "   Progress: 21760/28750 (75%)\n",
      "   Progress: 22080/28750 (76%)\n",
      "   Progress: 22400/28750 (77%)\n",
      "   Progress: 22720/28750 (79%)\n",
      "   Progress: 23040/28750 (80%)\n",
      "   Progress: 23360/28750 (81%)\n",
      "   Progress: 23680/28750 (82%)\n",
      "   Progress: 24000/28750 (83%)\n",
      "   Progress: 24320/28750 (84%)\n",
      "   Progress: 24640/28750 (85%)\n",
      "   Progress: 24960/28750 (86%)\n",
      "   Progress: 25280/28750 (87%)\n",
      "   Progress: 25600/28750 (89%)\n",
      "   Progress: 25920/28750 (90%)\n",
      "   Progress: 26240/28750 (91%)\n",
      "   Progress: 26560/28750 (92%)\n",
      "   Progress: 26880/28750 (93%)\n",
      "   Progress: 27200/28750 (94%)\n",
      "   Progress: 27520/28750 (95%)\n",
      "   Progress: 27840/28750 (96%)\n",
      "   Progress: 28160/28750 (97%)\n",
      "   Progress: 28480/28750 (99%)\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = utils.create_sentiment_table(df)\n",
    "\n",
    "df_sentiment.head()\n",
    "df_sentiment.to_csv('reddit_sentiment_backfill.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13a4cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-28 17:44:51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-08 14:48:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-12 12:08:07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-05 07:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-23 18:11:23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  sentiment\n",
       "0 2022-02-28 17:44:51          0\n",
       "1 2022-08-08 14:48:47          0\n",
       "2 2023-05-12 12:08:07          0\n",
       "3 2023-11-05 07:00:00          0\n",
       "4 2022-08-23 18:11:23          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d1df00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mean_sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  mean_sentiment  count\n",
       "0 2020-01-03        0.000000      1\n",
       "1 2020-01-11        0.000000      1\n",
       "2 2020-01-19        0.000000      1\n",
       "3 2020-02-05        0.333333      3\n",
       "4 2020-02-06        0.000000      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv('reddit_sentiment_backfill.csv', parse_dates=['timestamp'])\n",
    "df_agg_sentiment = utils.agregate_sentiment_table(df_sentiment)\n",
    "\n",
    "df_agg_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0d5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_sentiment.to_csv('reddit_aggregated_sentiment_backfill.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
